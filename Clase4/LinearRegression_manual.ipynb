{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Regresión Lineal (manual con pytorch):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciamos con la carga de las librerias que utilizaremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizaremos antes algunos aspectos de **pytorch**, primeramente como se crean tensores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(3.)\n",
    "w = torch.tensor(4., requires_grad=True)\n",
    "b = torch.tensor(5., requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.)\n",
      "tensor(4., requires_grad=True)\n",
      "tensor(5., requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Print tensors\n",
    "print(x)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nótese como algunas variables poseen la etiqueta `requires_grad=True` esto significa como se verá mas adelante que es posible calcular directamente las derivadas parciales de las variables que tengan este parámetro en `True`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los tensores creados anteriormente, podemos hacer operaciones aritméticas, en este caso construimos la ecuación de una linea recta e imprimimos el resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = w * x + b\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, calculamos las derivadas parciales de ***y*** respecto a las variables con `requires_grad=True` estas son `w` y `b`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute gradients\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dw: tensor(3.)\n",
      "dy/db: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Display gradients\n",
    "print('dy/dw:', w.grad)\n",
    "print('dy/db:', b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el panorama general de uso de ***pytorch*** para los propósitos de este ejercicio, ahora procedemos a analizar rapidamente los datos de nuestro problema:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Region | Temp (F) | Rain (mm) | Hum (%) | Apples (ton) | Oranges (ton)\n",
    "------------ | ------------- | ------------- | ------------- | ------------- | -------------\n",
    "Kanto | 73 | 67 | 43 | 56 | 70\n",
    "Johto | 91 | 88 | 64 | 81 | 101\n",
    "Hoenn | 87 | 134 | 58 | 119 | 133\n",
    "Sinnoh | 102 | 43 | 37 | 22 | 37\n",
    "Unova | 69 | 96 | 70 | 103 | 119\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea es crear un modelo de regresión lineal de la forma:\n",
    "    \n",
    "    yeild_apple  = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
    "    yeild_orange = w21 * temp + w22 * rainfall + w23 * humidity + b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "\\begin{array} { l l l l l } {X} & \\times & {W^{T}} & {+} & {b} \\end{array}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} {73} & {67} & {43} \\\\ {91} & {88} & {64} \\\\ {\\vdots} & {\\vdots} & {\\vdots} \\\\ {69} & {96} & {70} \\end{bmatrix} \\times \\begin{bmatrix}{w_{11}} & {w_{21}} \\\\ {w_{12}} & {w_{22}} \\\\ {w_{13}} & {w_{23}} \\end{bmatrix} + \\begin{bmatrix} {b_{1}} & {b_{2}} \\\\ {b_{1}} & {b_{2}} \\\\ {\\vdots} & {\\vdots} \\\\ {b_{1}} & {b_{2}} \\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos ahora los arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 73.,  67.,  43.],\n",
       "       [ 91.,  88.,  64.],\n",
       "       [ 87., 134.,  58.],\n",
       "       [102.,  43.,  37.],\n",
       "       [ 69.,  96.,  70.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 56.,  70.],\n",
       "       [ 81., 101.],\n",
       "       [119., 133.],\n",
       "       [ 22.,  37.],\n",
       "       [103., 119.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertimos ahora los `inputs` y los `targets` a tensores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo modelo de aprendizaje inicia con un conjunto de pesos random, en este caso creamos los tensores `w` y `b` random:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5410, -0.2934, -2.1788],\n",
      "        [ 0.5684, -1.0845, -1.3986]], requires_grad=True)\n",
      "tensor([0.4033, 0.8380], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "w = torch.randn(2, 3, requires_grad=True)\n",
    "b = torch.randn(2, requires_grad=True)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación definimos nuestro modelo, que correspondería a la ecuación de recta de la regresión lineal (no olvidar que el operador `@` sirve para multiplicar dos matrices o bien tensores tipo 2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def model(x):\n",
    "    return x @ w.t() + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora con los pesos aleatorios procedemos a hacer la predicción a partir del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  -0.4516,  -90.4691],\n",
      "        [ -24.6303, -132.3828],\n",
      "        [ -31.2192, -176.1530],\n",
      "        [  64.3523,  -39.5645],\n",
      "        [ -73.9524, -161.9561]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparamos con los datos originales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "# Compare with targets\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple vista se nota como los valores obtenidos en el modelo son bastante lejanos a los esperados, esto es normal, ya que no hemos usado ninguna técnica de optimización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tratemos de medir el error, en este caso con el ***MSE***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE loss\n",
    "def mse(t1, t2):\n",
    "    diff = t1 - t2\n",
    "    return torch.sum(diff * diff) / diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(33060.8047, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Compute loss\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nótese como el resultado anterior obtenido es un valor alto, se espera que este valor sea lo más bajo posible:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una tecníca de ***OPTIMIZACIóN*** muy común cosiste en el uso del gradiante descendiente, que corresponde a la derivada del error (en este caso el `loss` respecto a `w` y `b`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute gradients\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5410, -0.2934, -2.1788],\n",
      "        [ 0.5684, -1.0845, -1.3986]], requires_grad=True)\n",
      "tensor([[ -6938.4355,  -9674.6758,  -5744.0205],\n",
      "        [-17408.7871, -20595.9336, -12453.4707]])\n"
     ]
    }
   ],
   "source": [
    "# Gradients for weights\n",
    "print(w)\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4033, 0.8380], requires_grad=True)\n",
      "tensor([ -89.3802, -212.1051])\n"
     ]
    }
   ],
   "source": [
    "# Gradients for bias\n",
    "print(b)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que pytorch acumula los gradientes, debemos resetearlos a cero antes de seguir adelante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedemos ahora a contruir nuestro modelo con los ajustes al `w` y `b` usando el gradiante descendiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeramente generamos la primera predicción:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  -0.4516,  -90.4691],\n",
      "        [ -24.6303, -132.3828],\n",
      "        [ -31.2192, -176.1530],\n",
      "        [  64.3523,  -39.5645],\n",
      "        [ -73.9524, -161.9561]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora calculamos el `loss`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(33060.8047, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the loss\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora calculamos los gradientes para `loss` respecto a `w` y `b`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute gradients\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust weights & reset gradients\n",
    "with torch.no_grad():\n",
    "    w -= w.grad * 1e-5\n",
    "    b -= b.grad * 1e-5\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6104, -0.1967, -2.1213],\n",
      "        [ 0.7425, -0.8786, -1.2741]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora calculamos de nuevo el `loss`, debería ser menor que el anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23432.4902, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efectivamente es menor, sin embargo vemos que los resultados obtenidos difieren considerablemente de los esperados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  13.5663,  -58.6043],\n",
       "        [  -6.1255,  -90.4440],\n",
       "        [  -8.8863, -126.1837],\n",
       "        [  77.7158,   -8.3414],\n",
       "        [ -55.8554, -121.4523]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q/ Cómo se resuelve el problema de la optimización efectiva? \n",
    "\n",
    "R/ Se resuelve repitiendo el proceso múltiples veces, cada iteración se conoce como epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for 1000 epochs\n",
    "for i in range(1000):\n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds, targets)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= w.grad * 1e-5\n",
    "        b -= b.grad * 1e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.0205, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 57.5609,  70.6524],\n",
       "        [ 79.4107,  98.8859],\n",
       "        [124.4177, 136.4671],\n",
       "        [ 22.6800,  37.9871],\n",
       "        [ 96.2028, 115.6331]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos ahora como los valores son más cercanos a los deseados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
